{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominican-brown",
   "metadata": {},
   "source": [
    "# HW05 Subword_tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-andrews",
   "metadata": {},
   "source": [
    "## 1. –î–µ–ª–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é byte pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "actual-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix\n",
    "from collections import Counter, defaultdict\n",
    "from tokenizers import CharBPETokenizer, Tokenizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extra-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lenta.txt', 'r', encoding='utf-8') as f: text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mathematical-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[:50000].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civil-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(text):\n",
    "    frequencies = {}\n",
    "    for i in range(len(text)-1):\n",
    "        next_symbol = text[i+1]\n",
    "        pair = text[i] + next_symbol\n",
    "        if pair in frequencies:\n",
    "            frequencies[pair] += 1\n",
    "        else:\n",
    "            frequencies[pair] = 1\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "improved-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_most_freq(text, dictionary, k):\n",
    "    sort_dict = {}\n",
    "    keys = list(dictionary.keys())\n",
    "    keys = sorted(keys, key=lambda x: dictionary[x], reverse=True)\n",
    "    keys = keys[:k]\n",
    "    for key in keys:\n",
    "        sort_dict[key] = dictionary[key]\n",
    "    result = ()\n",
    "    process = True\n",
    "    for ind, sym in enumerate(text):\n",
    "        if process:\n",
    "            if ind < len(text)-1:\n",
    "                next_symbol = text[ind+1]\n",
    "            else:\n",
    "                result += tuple(sym, )\n",
    "                break\n",
    "            pair = sym + next_symbol\n",
    "            if pair in sort_dict: \n",
    "                result += (pair, )\n",
    "                process = False\n",
    "            else:\n",
    "                result += (sym, )\n",
    "        else:\n",
    "            process = True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alone-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe(text, n, k):\n",
    "    for i in range(n):\n",
    "        frequencies = statistics(text)\n",
    "        text = merge_most_freq(text, frequencies, k)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 3 ,k = 8\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 40539\n",
      "–±|–æ|–∏ |—É| —Å|–æ|–ø|–æ|—Ü|–∫|–∏|–Ω|–∞ |–∏ |–¥|—Ä|—É|—Å|–∫|–µ–Ω|–∏|–∫| |–∑|–∞|–∫–æ|–Ω|—á|–∏|–ª|–∏|—Å|—å| –æ|—Ç|—Å—Ç|—É|–ø|–ª|–µ–Ω|–∏|–µ|–º| |–≥|–µ—Ä|–º|–∞–Ω|—Ü|–µ|–≤|.| –Ω|–µ|–ø|—Ä|–∏|—è|—Ç|–µ–ª|—å|,| –ø|—Ä|–∏|–±|–ª|–∏|–∑|–∏|–≤|—à|–∏|—Å|—å| —Å| —Å|–µ|–≤|–µ—Ä|–∞ |–∫| –æ|—Å|–æ–≤|—Ü|—É| –Ω|–∞|—á|–∞|–ª| |–∞|—Ä|—Ç|–∏|–ª|–ª|–µ—Ä\n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: –∏ \n",
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 6 ,k = 15\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 32566\n",
      "–±–æ|–∏ |—É| —Å|–æ|–ø–æ|—Ü|–∫|–∏–Ω|–∞ |–∏ |–¥|—Ä—É|—Å–∫|–µ–Ω–∏|–∫| |–∑–∞|–∫–æ|–Ω|—á|–∏–ª|–∏|—Å|—å| –æ|—Ç|—Å—Ç|—É|–ø|–ª|–µ–Ω–∏|–µ|–º |–≥|–µ—Ä|–º|–∞–Ω|—Ü|–µ|–≤|. |–Ω–µ|–ø|—Ä–∏|—è|—Ç–µ|–ª—å|, |–ø|—Ä–∏|–±|–ª–∏|–∑|–∏|–≤|—à|–∏|—Å|—å| —Å| —Å|–µ|–≤|–µ|—Ä–∞| |–∫| –æ|—Å|–æ–≤|—Ü|—É| |–Ω–∞|—á|–∞–ª| |–∞—Ä|—Ç|–∏–ª|–ª|–µ—Ä|–∏|–π|—Å–∫|—É|—é| |–±–æ|—Ä|—å|–±|—É| —Å| |–∫|—Ä–µ|–ø–æ|—Å—Ç\n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: —á—Ç–æ \n",
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 9 ,k = 20\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 28708\n",
      "–±–æ|–∏ |—É| —Å–æ|–ø–æ|—Ü|–∫–∏|–Ω–∞ |–∏ |–¥|—Ä—É|—Å–∫|–µ–Ω–∏|–∫ |–∑–∞|–∫–æ–Ω|—á|–∏|–ª–∏|—Å|—å| –æ—Ç|—Å—Ç|—É–ø|–ª–µ–Ω–∏|–µ|–º |–≥|–µ—Ä|–º|–∞–Ω|—Ü|–µ|–≤|. |–Ω–µ|–ø—Ä–∏|—è|—Ç–µ–ª—å|, |–ø—Ä–∏|–±|–ª–∏|–∑|–∏|–≤|—à|–∏—Å|—å| —Å| —Å|–µ|–≤|–µ|—Ä–∞| |–∫| –æ|—Å|–æ–≤|—Ü|—É| –Ω–∞|—á|–∞–ª| |–∞—Ä|—Ç|–∏–ª|–ª|–µ—Ä|–∏|–π|—Å–∫|—É—é| –±|–æ—Ä|—å|–±|—É| —Å| |–∫|—Ä–µ|–ø–æ|—Å—Ç|—å|—é|.| –≤ |–∞—Ä|—Ç|–∏–ª|–ª|–µ—Ä|–∏|–π|—Å–∫–æ|–º |–±–æ\n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: –∏—Ç–µ–ª—å\n",
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 12 ,k = 30\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 24981\n",
      "–±–æ|–∏ |—É| —Å–æ|–ø–æ|—Ü|–∫–∏|–Ω–∞| –∏ |–¥|—Ä—É|—Å–∫|–µ–Ω–∏|–∫ |–∑–∞|–∫–æ–Ω|—á|–∏–ª|–∏—Å|—å| –æ—Ç|—Å—Ç—É–ø|–ª–µ–Ω–∏|–µ–º| –≥|–µ—Ä|–º|–∞–Ω|—Ü|–µ–≤|.| –Ω–µ|–ø—Ä–∏|—è|—Ç–µ–ª—å|, |–ø—Ä–∏|–±|–ª–∏|–∑–∏|–≤—à|–∏—Å|—å| —Å| —Å|–µ–≤|–µ—Ä|–∞ |–∫| –æ|—Å–æ–≤|—Ü|—É| –Ω–∞|—á|–∞–ª| |–∞—Ä—Ç–∏|–ª|–ª|–µ—Ä|–∏–π|—Å–∫|—É—é| –±|–æ—Ä|—å|–±—É| —Å| –∫|—Ä–µ|–ø–æ|—Å—Ç|—å|—é|.| –≤ |–∞—Ä—Ç–∏|–ª|–ª|–µ—Ä|–∏–π|—Å–∫–æ|–º |–±–æ|—é| –ø—Ä–∏|–Ω–∏|–º–∞|—é—Ç| —É|—á–∞—Å—Ç|–∏|–µ |—Ç|—è|–∂|–µ–ª|—ã|–µ \n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: —Å—Ç–≤–µ–Ω–Ω–æ\n",
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 16 ,k = 40\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 21688\n",
      "–±|–æ|–∏ |—É| —Å–æ|–ø–æ|—Ü|–∫–∏|–Ω–∞| –∏| –¥—Ä—É|—Å–∫|–µ–Ω–∏|–∫| –∑–∞|–∫–æ–Ω|—á–∏|–ª–∏—Å—å| –æ—Ç|—Å—Ç—É–ø|–ª–µ–Ω–∏|–µ–º| |–≥|–µ—Ä|–º|–∞–Ω|—Ü|–µ–≤|. |–Ω–µ|–ø—Ä–∏|—è—Ç–µ–ª—å|, |–ø—Ä–∏|–±–ª–∏|–∑–∏|–≤—à–∏|—Å—å| —Å| —Å|–µ|–≤–µ—Ä|–∞ |–∫| –æ|—Å–æ–≤|—Ü|—É| –Ω–∞|—á–∞|–ª| |–∞—Ä—Ç–∏|–ª|–ª|–µ—Ä–∏|–π—Å–∫|—É—é| –±|–æ—Ä|—å|–±—É| —Å| –∫|—Ä–µ|–ø–æ|—Å—Ç|—å—é|. –≤ |–∞—Ä—Ç–∏|–ª|–ª|–µ—Ä–∏|–π—Å–∫–æ|–º| –±|–æ|—é| –ø—Ä–∏|–Ω–∏|–º–∞|—é—Ç| —É—á–∞—Å—Ç|–∏|–µ |—Ç|—è|–∂|–µ–ª|—ã|–µ |–∫–∞|–ª–∏|–±|—Ä—ã|. —Å| —Ä|–∞–Ω|–Ω–µ\n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π:  –ø—Ä–∞–≤–∏—Ç–µ–ª—å\n",
      "--------------------------------------------------\n",
      "–ø—Ä–∏ n = 20 ,k = 50\n",
      "–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: 19305\n",
      "–±–æ|–∏ |—É| —Å–æ|–ø–æ|—Ü|–∫–∏|–Ω–∞| –∏| –¥|—Ä—É|—Å–∫|–µ–Ω–∏|–∫| –∑–∞|–∫–æ–Ω|—á–∏|–ª–∏—Å—å| –æ—Ç|—Å—Ç—É–ø|–ª–µ–Ω–∏|–µ–º| –≥|–µ—Ä|–º–∞–Ω|—Ü–µ|–≤|. |–Ω–µ|–ø—Ä–∏|—è—Ç–µ–ª—å|, |–ø—Ä–∏|–±–ª–∏|–∑–∏|–≤—à–∏|—Å—å| —Å| —Å–µ|–≤–µ—Ä|–∞ |–∫| –æ|—Å–æ–≤|—Ü—É| –Ω–∞|—á–∞|–ª |–∞—Ä—Ç–∏–ª–ª–µ—Ä–∏|–π—Å–∫|—É—é| –±|–æ—Ä|—å|–±—É| —Å| –∫|—Ä–µ|–ø–æ|—Å—Ç|—å—é|. –≤ |–∞—Ä—Ç–∏–ª–ª–µ—Ä–∏|–π|—Å–∫–æ–º| –±–æ|—é| –ø—Ä–∏|–Ω–∏|–º–∞|—é—Ç| —É—á–∞—Å—Ç|–∏|–µ |—Ç|—è|–∂|–µ–ª|—ã|–µ |–∫–∞|–ª–∏|–±|—Ä—ã|. —Å| —Ä–∞–Ω|–Ω–µ|–≥–æ| —É|—Ç—Ä–∞| 1|4| —Å–µ–Ω—Ç—è–±—Ä—è |–æ–≥–æ|–Ω—å| –¥|–æ—Å|—Ç–∏|–≥| –∑\n",
      "–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: —Ä–∞—á–∞–µ–≤–æ-—á–µ—Ä–∫–µ—Å–∏\n"
     ]
    }
   ],
   "source": [
    "n = [3, 6, 9, 12, 16, 20]\n",
    "k = [8, 15, 20, 30, 40, 50]\n",
    "\n",
    "for i,j in zip(n, k):\n",
    "    result = bpe(text, i, j)\n",
    "    print('--------------------------------------------------')\n",
    "    print('–ø—Ä–∏ n = ' + str(i), ',k = ' + str(j))\n",
    "    print('–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: ' + str(len(result)))\n",
    "    print('|'.join(result[:100]))\n",
    "    print('–°–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π: ' + str(sorted(result, key=lambda x: len(x), reverse=True)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-survey",
   "metadata": {},
   "source": [
    "–û–Ω —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –∫–∞–∫–∏–µ-—Ç–æ —á–µ—Ä—Ç—ã —Ç–æ–∫–µ–Ω–æ–≤, –±–ª–∏–∑–∫–∏—Ö –∫ –º–æ—Ä—Ñ–µ–º–∞–º, –ø—Ä–æ–≥–ª—è–¥—ã–≤–∞—é—Ç—Å—è. –ü–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —á–µ–º –±–æ–ª—å—à–µ n –∏ k, —Ç–µ–º –ª—É—á—à–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-intellectual",
   "metadata": {},
   "source": [
    "### 2. –û–±—É—á–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏–∑ tokenizers –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –∫–æ—Ä–ø—É—Å–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "leading-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–Ω–∞–µ–±–∞–ª–æ–≤–æ –≤–µ–∫–∞, –¥–ª—è –¥–æ–ª–±–∞—ë–±–æ–≤\\n</td>\n",
       "      <td>INSULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–≤—Å—è –¥—É–º–∞ –≤ —Ç–∞–∫–æ–º –∂–µ –ø–æ–ª–æ–∂–µ–Ω–∏–∏üòÅ\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–∞ –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –º–∞—Å—Å–æ–≤–æ–µ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–µ? —à—Ä–∞–π–±–∏–∫...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–∑–Ω–∞—á–∏—Ç –ª–∏ —ç—Ç–æ, —á—Ç–æ –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –≤—ã–≤–æ–∑–æ–º –∫—Ä—É–ø–Ω–æ–≥...</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–≤–∞–º –Ω–µ –Ω—É–∂–µ–Ω —â–µ–Ω–æ—á–µ–∫? –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ üê∂ü•∞\\n</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0                    –Ω–∞–µ–±–∞–ª–æ–≤–æ –≤–µ–∫–∞, –¥–ª—è –¥–æ–ª–±–∞—ë–±–æ–≤\\n  INSULT\n",
       "1                   –≤—Å—è –¥—É–º–∞ –≤ —Ç–∞–∫–æ–º –∂–µ –ø–æ–ª–æ–∂–µ–Ω–∏–∏üòÅ\\n  NORMAL\n",
       "2  –∞ –≤ –∫–∞–∫–æ–º –º–µ—Å—Ç–µ –º–∞—Å—Å–æ–≤–æ–µ —Å—Ç–æ–ª–∫–Ω–æ–≤–µ–Ω–∏–µ? —à—Ä–∞–π–±–∏–∫...  NORMAL\n",
       "3  –∑–Ω–∞—á–∏—Ç –ª–∏ —ç—Ç–æ, —á—Ç–æ –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –≤—ã–≤–æ–∑–æ–º –∫—Ä—É–ø–Ω–æ–≥...  NORMAL\n",
       "4           –≤–∞–º –Ω–µ –Ω—É–∂–µ–Ω —â–µ–Ω–æ—á–µ–∫? –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ üê∂ü•∞\\n  NORMAL"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset_ok.csv')\n",
    "data = df['text'].tolist()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "northern-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].to_csv('data/data.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "false-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtoken = CharBPETokenizer()\n",
    "subtoken.train('data/data.txt', vocab_size=3000)\n",
    "\n",
    "subtoken.save('subtoken')\n",
    "subtoken = Tokenizer.from_file('subtoken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cheap-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "K = len(subtoken.get_vocab())\n",
    "\n",
    "X = lil_matrix((N, K))\n",
    "X_idf = lil_matrix((N, K))\n",
    "\n",
    "for i, text in enumerate(data):\n",
    "    token_ids = subtoken.encode(text).ids\n",
    "    for t in token_ids:\n",
    "        X[i, t] += 1\n",
    "        if X_idf[i, t] == 0:\n",
    "            X_idf[i, t] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nervous-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.Series(X_idf.sum(axis=0).tolist()[0])\n",
    "idf = idf.apply(lambda x: np.log((1 + idf.shape[0]) / (1 + x)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interracial-greeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2997    3.683691\n",
       "2998    3.733701\n",
       "2999    3.678825\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "explicit-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.multiply(lil_matrix(idf.tolist()))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.2, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "convenient-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9284598 , 0.92160097, 0.92646293, 0.9275916 , 0.9260224 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SGDClassifier(loss=\"log\", max_iter=30)\n",
    "cross_val_score(classifier, X_train, y_train, scoring=\"f1_micro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
