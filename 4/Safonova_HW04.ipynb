{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "communist-georgia",
   "metadata": {},
   "source": [
    "# HW04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-taiwan",
   "metadata": {},
   "source": [
    "## 1. Преобразуем таблицу с абсолютными частотностями в таблицу с tfidf значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "posted-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/47bRcVy/bow-normalized.jpg\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "IMG_URL = 'https://i.ibb.co/47bRcVy/bow-normalized.jpg'\n",
    "Image(url=IMG_URL, width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expired-saying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/safonovanastya/hse_comp_ling/main/4/Screenshot.png\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_URL = 'https://raw.githubusercontent.com/safonovanastya/hse_comp_ling/main/4/Screenshot.png'\n",
    "Image(url=IMG_URL, width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-force",
   "metadata": {},
   "source": [
    "## 2а) Посчитаем близость между 3 и 12666 текстами в датасете (labeled.csv из семинара) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removable-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sitting-superior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeled.csv')\n",
    "df.comment = df.comment\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "data = vect.fit_transform(df.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aggregate-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "близость: 0.27330886297549256\n"
     ]
    }
   ],
   "source": [
    "print('близость: ' + str(cosine_similarity(data[3], data[12666][0][0])[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-mixer",
   "metadata": {},
   "source": [
    "## 2б) Найдём 3 самых близких текста к тексту номер 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "colored-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1986 1957 6259] [0.83956018 0.88210851 0.88590919]\n"
     ]
    }
   ],
   "source": [
    "closest = cosine_distances(data[43], data).argsort()[0,1:4]\n",
    "proximity = np.sort(cosine_distances(data[43], data))[0,1:4]\n",
    "print(closest, proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "written-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1986 1957 6259]\n"
     ]
    }
   ],
   "source": [
    "print(closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rotary-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "текст: НУ И КАКАЯ МРАЗЬ КИДАЕТ ССЫЛКИ? ОХУЕЛИ ТАМ В КРАЙ УЖЕ?\n",
      "\n",
      "близость: 0.16043982092396114\n",
      "текст: Че за бригада и че за махоун? Из полицейской академии?\n",
      "близость: 0.11789148760536672\n",
      "текст: Герка ебет только даунов которые игрли а него. Ибо и геймплей и сюжетто кусок говна.\n",
      "\n",
      "близость: 0.11409080923099102\n"
     ]
    }
   ],
   "source": [
    "for ind, n in enumerate(closest):\n",
    "    print('текст: ' + df.loc[n].comment)\n",
    "    print('близость: ' + str(1 - proximity[ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-smile",
   "metadata": {},
   "source": [
    "## 3. Обучим 2 любых классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "liable-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.comment, df.toxic, test_size=0.1, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-event",
   "metadata": {},
   "source": [
    "### 1 -- Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "divine-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count = CountVectorizer(ngram_range=(1,2), max_df=0.85, min_df=2,\n",
    "                             stop_words=stops, analyzer='char_wb')\n",
    "X_train_count = vect_count.fit_transform(X_train)\n",
    "X_test_count = vect_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "owned-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86       931\n",
      "         1.0       0.71      0.83      0.77       511\n",
      "\n",
      "    accuracy                           0.82      1442\n",
      "   macro avg       0.81      0.82      0.81      1442\n",
      "weighted avg       0.83      0.82      0.82      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastia/miniconda3/envs/python3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "lr.fit(X_train_count, y_train)\n",
    "\n",
    "preds = lr.predict(X_test_count)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-semester",
   "metadata": {},
   "source": [
    "### 2 -- Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "canadian-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(ngram_range=(1,2), min_df = 3, max_df = 0.95, max_features = 1000, token_pattern=r'(?u)\\b\\w+\\b')\n",
    "\n",
    "X_train_vect = vect_tfidf.fit_transform(X_train)\n",
    "X_test_vect = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "narrative-matter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.79      0.78       931\n",
      "         1.0       0.59      0.55      0.57       511\n",
      "\n",
      "    accuracy                           0.71      1442\n",
      "   macro avg       0.68      0.67      0.67      1442\n",
      "weighted avg       0.70      0.71      0.70      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dec_tree = DecisionTreeClassifier(criterion='entropy', max_depth=30, random_state=127, min_samples_split=2)\n",
    "dec_tree.fit(X_train_vect, y_train)\n",
    "\n",
    "preds = dec_tree.predict(X_test_vect)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-ensemble",
   "metadata": {},
   "source": [
    "### Работа с корпусом Dvach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wound-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach = open('data/2ch_corpus.txt', encoding=\"utf-8\").readlines()[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "resident-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach_count = vect_count.transform(dvach)\n",
    "dvach_vect = vect_tfidf.transform(dvach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acceptable-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach_lr_proba = lr.predict_proba(dvach_count)\n",
    "\n",
    "dvach_dt_proba = dec_tree.predict_proba(dvach_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "backed-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_top10 = dvach_lr_proba[:,1].argsort()[::-1][:10]\n",
    "lr_top10_proba = dvach_lr_proba[lr_top10, 1]\n",
    "\n",
    "dt_top10 = dvach_dt_proba[:,1].argsort()[::-1][:10]\n",
    "dt_top10_proba = dvach_dt_proba[dt_top10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "imported-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ВИЧУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУЧУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУЧУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУЧУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУУХА БЛЯЯЯЯЯЯЯЯ\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Ёбаные советские названия блять. КРУЖКИ блять. Всегда ненавидел. Блять. Почему бы не сказать КЛУБ ПО ИНТЕРЕСАМ, как у япошек, нет блять, будем гуманитарную хуйню, сравнения блять, типа В КРУГ СОБРАЛИСЬ, ахахахаха кружок ахахахахаха))))) пиздец блять. Может при Сталине это звучало, но уже при Горбачёве это просто бесило, а сейчас это выглядит вообще как атавизм. Или ещё ебанутое слово СЛЁТ блять. Сука, СЛЁТ, почему слёт, а не съезд? Типа съезд - это для КПСС, не доросли ещё? Или типа в Совке так всё пиздато, что даже у школия есть своё самолёт? СЛЁТ сука, мы что, блять, стрижи? Или это какая-то аллегория на ёбаных ОРЛЯТ? Вот тоже заебучее сравнение, всегда бесило, ОРЯЛА УЧАТСЯ ЛЕТАТЬ, блять, да мне похуй на каких-то куриц, орлят, блять, голубей, петухов, учатся они летать блять, а страусы вон не учатся, мне-то что до ваших сраных ОРЛЯТ, пел всегда КОЛЗЛЯТ, да-да, школие, этот прикол существовал ещё до Задорнова и прочих клованов - в совковых песнях заменять \"орёл\" на \"козёл\". Ну до чего же сука поганая страна была, хорошо, что развалилась нахуй!\n",
      "\n",
      "токсик на 99.99999996129856%\n",
      "===========================================================================\n",
      " >удел школоты>говорит это 32-лвл куну, познавшему дзен Молодой человек, если ты слушаешь музыку, ориентируясь исключительно на \"допустимый для прослушивания\" возраст/статус, то у меня для тебя никаких новостей, лол, ты проёбан. Музыку надо любить. А денег на яхту у меня уже есть, просто на маленькую, да только нахуй в ДС яхта-то? Дозаведу трактор - можно озаботиться. Это ж не приоритетная потребность. К слову, спокойную музыку я тоже люблю. Но не будешь же ты ебошить с яхты Свиридова или там я не знаю, Fourplay. Это не яхтная музыка, лол. А экстремальный металл, в свою очередь, - не напряг. Для меня, к примеру, тот же Decapitated - вообще идеальный чиллаут: хорошо записан, не слишком заумен, чтобы вслушиваться вот прямо, хорошая полиритмия, которая мне очень доставляет, эмоции, блять, подача.\n",
      "\n",
      "токсик на 99.9999407547431%\n",
      "===========================================================================\n",
      " Вместо того, что бы радоваться тому, что человек в 50 лет может веселиться, трахать молодых тян, зарабатывать бабло, двачер тупо разрывает сам себе жопу. А потом жалуется, что 25 лет это уже старость и все проебано. Да вы ж дебилы нахуй. Вот вам реальный пример человека, который смог. Он разорвал ваш манямир. Да вот проблема в том, что вам уютно в этом манямире. Вы хотите быть унылыми нищебродами с нестоящей писькой, вы хотите страдать, вы хотите жить в говне. Но вы в этом никогда не признаетесь. Продолжайте батхердить.\n",
      "\n",
      "токсик на 99.99960440977506%\n",
      "===========================================================================\n",
      " >доказывать свой социальный статус телом без татух Я аж ахуел. Значит если я не бью тату - я что-то доказываю? Мужик молодец конечно, но в начале треда какой-то вялый жир. Горело всегда не из-за денег, а из-за тупости и желания засветится, похвастаться хуергой, псевдотяжелым путем к успеху. Как у практически всех наших звезд первой величины. Нахуя если ты успешный и все об этом знают, сраными портаками себя покрывать и постить хуету в социалочках? Вот как раз пизду Барановскую вспоминал сегодня, ну отпилила кусок от Андрейки нахаляву, нет надо еще карусель с токшоу устроить о том, какая талантливая ведущая и журналистка обиженная жизнью и пришедшая ко всему сама. Счастлив и счастлив, а это какая-то тупопёздность. Что собственно здесь и цитируют:>в жизни каждого человека наступает тот момент, когда нужно решить, «оказаться испачканным внутри или снаружи», и сам он выбрал внутреннюю чистоту Пойду говном измажусь, момент настал похоже.\n",
      "\n",
      "токсик на 99.99793901298067%\n",
      "===========================================================================\n",
      " В каком там классе учили уравнения составлять? шахматисты + танцоры + шахматисты_танцоры = 56шахматисты + шахматисты_танцоры = 28танцоры + шахматисты_танцоры = 48танцоры - 28шахматисты_танцоры - 20шахматисты - 8\n",
      "\n",
      "токсик на 99.99545104271988%\n",
      "===========================================================================\n",
      " Набежали хохлы дауны которы не смогли решить задачу, обиделись, и во всем виноват совок) хохлы - такие хохлы\n",
      "\n",
      "токсик на 99.99268402866454%\n",
      "===========================================================================\n",
      " Он охуенный только для тупых примитивных школьников тебя. УУУ ТЁЛАЧКИ УУУ МНОГА ДЕНЕХ, ОЛЬФА-СОМЕЦ. Есть богачи типа Маска, которые хотя бы немного двигают мир вперёд. А есть мрази, которые только потребляют. Нахуярился стероидов, повертел жопой вместе с какими-то шалавами - стал кумиром для быдла вроде тебя.\n",
      "\n",
      "токсик на 99.99143780629807%\n",
      "===========================================================================\n",
      "  ммм, из разряда \" у тебя так бомбит потому что ты не хохол\" где связь между мясными хохлами которых пиздят и евровидением? Я эту хуйню никогда не смотрел и вообще похуй на нее\n",
      "\n",
      "токсик на 99.98879694560179%\n",
      "===========================================================================\n",
      " А теперь почитайте что пишут всякие пезды и охуейте такой секси мм Пиздец. Какая-то марамойка в своих мечтах представляет что он увидит её камент, бросит свою пизду, заберет шлюху из Рахи и будет пялить. А она ему борщи и личиноккоторых он ненавидит будет рожать.\n",
      "\n",
      "токсик на 99.9846461763759%\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(lr_top10):\n",
    "    print(dvach[i])\n",
    "    print('токсик на ' + str(lr_top10_proba[ind]*100) + '%')\n",
    "    print('===========================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "silent-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Анимублядский WebM-треддля приличных анимублядей и прочих аутистов. Безграмотное быдло с дубляжом, войсовером, порнографией и котиками, советы мерзких мокрописечников, вниманиебляди всех видов и прочее непотребство отправляется в порнотред <ссылка>.Для поиска сoуса видео сохраняем кадр (правый клик по видео) и ищем его на Для воспроизведения WebM с 10-битным цветом нужно установить плагин vlc ( ) и отключить встроенный в браузер плеер (media. webm. enabled=false в firefox).О кодировании WebMДоступные кодеки — VP8 и VP9 для видео, Vorbis и Opus для звука, максимальный размер файла — 10240КБ, всех файлов в посте — около 40МБ. Делать WebM можно научиться в вики треда: Там находится подробная информация о выборе и настройке кодеков на примерах использования консольных утилит ffmpeg, vpxenc и mkvmerge. Неочевидные моменты— libvorbis при указании битрейта (-b:a) работает в режиме CBR (постоянный битрейт), и это портит качество звука; для режима VBR вместо битрейта надо указывать качество (-q:a); параметр -vbr on работает только для Opus'а;— в webm'ки не нужно включать софтсаб в формате webvtt (FFmpeg это делает по умолчанию при наличии сабов в контейнере, отключается параметром -sn): во-первых, это бесполезно (для его отображения на странице должен быть специальный код), а во-вторых, от этого ролики не воспроизводятся в firefox. Программы и их документация Фронтенды к ffmpeg для кодирования вебмокCLI, бидон: zsh: дотнет: дотнет: Оп-паста: \n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Связи получаются только если самому шарить и шариться. Например, решил в бизнес - звонишь-ездишь по всяким поставщикам, складам, офисам (ты решаешь свою проблему), хуякс, и у тебя уже полон телефон потенциальных связей.\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      "  Ты знаешь, а он в чём-то прав\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Самое неожиданно место для пирсинга у девушки - это ее хуй.\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Нахуя такие выебоны? Чтобы быдло типа посетителей этого треда и комментаторов в инсте слюни пускало? Разве в этом счастье?\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      "  Ну, для начала, пойми с кем ты хочешь говорить. Если твои быдлоклассники на перемене что-то там пиздят, то на это внимания можешь не обращать вообще. Найди людей, которые реально тебе важны только не ставь их выше себя никогда, тогда общение само по себе пойдет. Вместе с определением круга общения придут и нужные темы для разговора. Суть же в том, чтобы разговор эффективным был. Ну и все.\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " А почему нельзя остаться чистым целиком? Или ему что предлагали, \"В жопу раз или партаки на вас?\"\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Все тот же хирург. Вызывай скорую, говори что у тебя интоксикация, и пиздуй в хирургтческое отделение пиздошить себе аппендюк\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      "  Не надо стесняться своего характера, дебил. Тебе всё равно не стать жизнерадостным рубаха-парнем.\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n",
      " Скорее всего эпигастральная фаза аппендицита, вызывай скорую говорю же, вангую что по анализам лейкоцитоз будет, если ты с дс приезжай я тебя прооперирую, как раз дежцрю седня)\n",
      "\n",
      "токсик на 100.0%\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "for ind, i in enumerate(dt_top10):\n",
    "    print(dvach[i])\n",
    "    print('токсик на ' + str(dt_top10_proba[ind]*100) + '%')\n",
    "    print('===========================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-creator",
   "metadata": {},
   "source": [
    "Тексты не пересекаются. \n",
    "\n",
    "В логистической регрессии как токсичный отмечен немного странный комментарий \"В каком там классе учили уравнения составлять? шахматисты + танцоры + шахматисты_танцоры = 56шахматисты + шахматисты_танцоры = 28танцоры + шахматисты_танцоры = 48танцоры - 28шахматисты_танцоры - 20шахматисты - 8\" и самый первый, который он определил на 100% токсичный тоже немного странный, все остальные вплоне токсичны.\n",
    "\n",
    "Дерево решений справилось чуть хуже, попадаются очевидно не токсичные комментарии (например, \"Ты знаешь, а он в чём-то прав\" или \"Скорее всего эпигастральная фаза аппендицита, вызывай скорую говорю же, вангую что по анализам лейкоцитоз будет, если ты с дс приезжай я тебя прооперирую, как раз дежцрю седня)\"). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
